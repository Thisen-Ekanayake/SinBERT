{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf37dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading dataset...\n",
      "\n",
      "=== DATASET SUMMARY ===\n",
      "Total blocks     : 7\n",
      "Input shape      : torch.Size([31])\n",
      "Label shape      : torch.Size([31])\n",
      "\n",
      "=== BLOCK 6 ===\n",
      "Input token IDs:\n",
      "[183, 3455, 2972, 25457, 1279, 1279, 472, 21717, 53, 10605, 4, 3, 951, 450, 107, 1077, 347, 3, 797, 5, 1508, 5, 481, 5, 1501, 10, 448, 2362, 580, 10, 786]\n",
      "\n",
      "Decoded text (input_ids):\n",
      "--------------------------------------------------------------------------------\n",
      "කගිසෝ රබාඩා පිට පිට කඩුලු ත්‍රිත්වයක් ලබා ගැනීමය. 100 ට වැඩි තද වැසි බස්නාහිර, සබරගමුව, මධ්‍යම, වයඹ සහ උතුරු පළාත්වලත් ගාල්ල සහ මාතර\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== LAST BLOCK PREVIEW ===\n",
      "--------------------------------------------------------------------------------\n",
      "කගිසෝ රබාඩා පිට පිට කඩුලු ත්‍රිත්වයක් ලබා ගැනීමය. 100 ට වැඩි තද වැසි බස්නාහිර, සබරගමුව, මධ්‍යම, වයඹ සහ උතුරු පළාත්වලත් ගාල්ල සහ මාතර\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "\n",
    "# -------- CONFIG --------\n",
    "PT_FILE = \"train_blocks.pt\"\n",
    "TOKENIZER_MODEL = \"tokenizer/unigram_32000_0.9995.model\"\n",
    "\n",
    "SHOW_TOKENS = True      # set True to see raw token ids\n",
    "PREVIEW_TOKENS = 200     # how many tokens to decode\n",
    "BLOCK_INDEX = 6          # change to inspect another block\n",
    "# ------------------------\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(TOKENIZER_MODEL)\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = torch.load(PT_FILE, map_location=\"cpu\")\n",
    "\n",
    "print(\"\\n=== DATASET SUMMARY ===\")\n",
    "print(f\"Total blocks     : {len(dataset)}\")\n",
    "\n",
    "sample = dataset[0]\n",
    "print(f\"Input shape      : {sample['input_ids'].shape}\")\n",
    "print(f\"Label shape      : {sample['labels'].shape}\")\n",
    "\n",
    "# -------- Inspect a specific block --------\n",
    "block = dataset[BLOCK_INDEX]\n",
    "input_ids = block[\"input_ids\"].tolist()\n",
    "labels = block[\"labels\"].tolist()\n",
    "\n",
    "print(f\"\\n=== BLOCK {BLOCK_INDEX} ===\")\n",
    "\n",
    "if SHOW_TOKENS:\n",
    "    print(\"Input token IDs:\")\n",
    "    print(input_ids[:PREVIEW_TOKENS])\n",
    "\n",
    "print(\"\\nDecoded text (input_ids):\")\n",
    "print(\"-\" * 80)\n",
    "print(sp.decode(input_ids[:PREVIEW_TOKENS]))\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# -------- Inspect last block (optional) --------\n",
    "last_block = dataset[-1][\"input_ids\"].tolist()\n",
    "\n",
    "print(\"\\n=== LAST BLOCK PREVIEW ===\")\n",
    "print(\"-\" * 80)\n",
    "print(sp.decode(last_block[:PREVIEW_TOKENS]))\n",
    "print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
